# Emotion-Detection-and-Helper
[사람의 감정을 인식해서 그에 어울리는 사진과 음악을 출력해준다. 4개국어(영어, 한국어, 카자흐어, 러시아어)로 구성되어 있다]

이 프로젝트는 사람의 얼굴을 인식해서, 현재 상태를 파악합니다. 그리고 그 감정에 맞는 사진을 출력하고, 음악 들려줍니다.
감정은 총 5개의 class로 나눴습니다: happy, sad, expressionless, surprise, angry.

데이터을 수집 시 구글과 러시아어 기반 검색 엔진 "Yandex"를 사용했습니다. Google에서의 검색 결과는 대부분의 사진들은 대부분 유료 사진이거나 화질이 떨어지는 사진
들이었습니다. 그러나 Yandex에서의 검색 결과는 무료이면서 고화질의 사진들이었습니다. 또한 사진 검색하면서 특정 감정, 특히 슬픔과 분노와 같은 부정적 감정을 나타내는 사진을 찾기 어려웠습니다. 이는 사람들이 부정적인 감정을 숨기려는 심리적 경향성을 반영하는 것으로 보입니다. 대다수의 사람들이 긍정적이고 행복한 모습만을 드러내려는 경향이 있음을 확인할 수 있었습니다. 데이터를 모을 때 최대한 인종, 성별에 맞춰서 해보려고 했습니다

다음은 50장씩 250장 모은 데이터셋입니다. 
happy : 총 50장 (동양 남자 9, 동양 여자 9, 서양 남자 8, 서양 여자 8, 흑인 남자 7, 흑인 여자 9)
sad : 총 50장 (동양 남자 9, 동양 여자 8, 서양 남자 7, 서양 여자 9, 흑인 남자 7, 흑인 여자 10)
expressionless : 총 50장 (동양 남자 8, 동양 여자 8, 서양 남자 9, 서양 여자 10, 흑인 남자 7, 흑인 여자 8)
surprise : 총 50장 (동양 남자 8, 동양 여자 10, 서양 남자 7, 서양 여자 8, 흑인 남자 8, 흑인 여자 9)
angry : 총 50장 (동양 남자 8, 동양 여자 9, 서양 남자 9, 서양 여자 8, 흑인 남자 8, 흑인 여자 8)
![image](https://github.com/aikozvezda/Emotion-Detection-and-Helper/assets/144213771/af3a7b3e-fd09-49a1-8c7d-da70ddaa94c9)

근데 여기서 데이터가 적다고 생각해서, 데이터의 양을 augmentation을 이용해서 늘려봤습니다.
happy : 352장
sad : 347장
expressionless : 346장
surprise : 344장
angry : 346장


